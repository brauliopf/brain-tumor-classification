{"cells":[{"cell_type":"markdown","metadata":{},"source":["# Set up environment"]},{"cell_type":"code","execution_count":1,"metadata":{"executionInfo":{"elapsed":168,"status":"ok","timestamp":1730947419634,"user":{"displayName":"Braulio Fernandes","userId":"15281912688788735537"},"user_tz":300},"id":"P13JgdPw01Hp"},"outputs":[],"source":["# !pip install pyngrok\n","# !pip install streamlit\n","# !pip install python-dotenv\n","# !pip install google-generativeai --upgrade\n","# !pip install tensorflow\n","# !pip install plotly\n","# !pip install opencv-python"]},{"cell_type":"code","execution_count":2,"metadata":{"executionInfo":{"elapsed":5,"status":"ok","timestamp":1730947419956,"user":{"displayName":"Braulio Fernandes","userId":"15281912688788735537"},"user_tz":300},"id":"1_wV9A6wvvqL"},"outputs":[],"source":["import os\n","import streamlit as st\n","import subprocess\n","from threading import Thread\n","from pyngrok import ngrok\n","from dotenv import load_dotenv\n","load_dotenv();"]},{"cell_type":"code","execution_count":3,"metadata":{"executionInfo":{"elapsed":7,"status":"ok","timestamp":1730947419807,"user":{"displayName":"Braulio Fernandes","userId":"15281912688788735537"},"user_tz":300},"id":"pcROA-S33NSo"},"outputs":[],"source":["def disconnect_ngrok_tunnels(ngrok):\n","    tunnels = ngrok.get_tunnels()\n","    for tunnel in tunnels:\n","      ngrok.disconnect(tunnel.public_url)\n","    return None"]},{"cell_type":"code","execution_count":4,"metadata":{"executionInfo":{"elapsed":644,"status":"ok","timestamp":1730947420596,"user":{"displayName":"Braulio Fernandes","userId":"15281912688788735537"},"user_tz":300},"id":"JupD0Kq00v_o"},"outputs":[],"source":["ngrok_token = os.getenv(\"NGROK_AUTH_TOKEN\")\n","ngrok.set_auth_token(ngrok_token)"]},{"cell_type":"code","execution_count":5,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":154,"status":"ok","timestamp":1730947419955,"user":{"displayName":"Braulio Fernandes","userId":"15281912688788735537"},"user_tz":300},"id":"ysR5FeNSKwBT","outputId":"f2e86659-13af-474f-fd4c-e36c336879bc"},"outputs":[],"source":["disconnect_ngrok_tunnels(ngrok)"]},{"cell_type":"code","execution_count":6,"metadata":{"executionInfo":{"elapsed":15,"status":"ok","timestamp":1730947420598,"user":{"displayName":"Braulio Fernandes","userId":"15281912688788735537"},"user_tz":300},"id":"WNjuGNYV2YTn"},"outputs":[],"source":["def run_streamlit(port = 3005):\n","  # Streamlit Cloud runs commands from the root folder, so \"src\" creates a conflict with testing and production envs\n","  # In order to emulate production, we need to run commands from the root folder\n","  os.chdir(\"..\")\n","  os.system(f\"streamlit run ./src/app.py --server.port {port}\")"]},{"cell_type":"markdown","metadata":{},"source":["# Build Streamlit App"]},{"cell_type":"markdown","metadata":{},"source":["## Explain prediction with GenAI"]},{"cell_type":"code","execution_count":7,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":14,"status":"ok","timestamp":1730947420598,"user":{"displayName":"Braulio Fernandes","userId":"15281912688788735537"},"user_tz":300},"id":"k7b6x7zh74qp","outputId":"165a7d31-4587-43de-afa8-bd38ef0061c8"},"outputs":[{"name":"stdout","output_type":"stream","text":["Overwriting app.py\n"]}],"source":["%%writefile app.py\n","\n","import tensorflow as tf\n","import numpy as np\n","import plotly.graph_objects as go\n","import cv2 # included in module: opencv-python\n","\n","import google.generativeai as genai\n","import PIL.Image\n","import os\n","from dotenv import load_dotenv\n","\n","load_dotenv();\n","# tell collab to create the tile with the output of this cell\n","\n","import google.generativeai as genai\n","import os\n","import streamlit as st\n","\n","from tensorflow.keras.models import load_model\n","from tensorflow.keras.preprocessing import image\n","from tensorflow.keras.models import Sequential\n","from tensorflow.keras.layers import Dense, Dropout, Flatten\n","from tensorflow.keras.optimizers import Adamax\n","from tensorflow.keras.metrics import Precision, Recall\n","\n","genai.configure(api_key=os.getenv(\"GOOGLE_API_KEY\"))\n","\n","output_dir = 'saliency_maps'\n","os.makedirs(output_dir, exist_ok=True)\n","\n","# this is a multimodal prompt. it has a text body and an image attachment\n","# tips to improve prompt\n","# - guide for a shorter or more sturctured output\n","# - tell it to think step-by-step (and verify each step)\n","# - get an llm to create a prompt\n","# - play with different roles (medical specialty)\n","def generate_explanation(img_path, model_prediction, confidence):\n","    prompt = f\"\"\"You are an expert neurologist. You are tasked with explaining a saliency map of a brain tumor MRI scan.\n","    The saliency map was generated by a deep learning model that was trained to classify brain tumors\n","    as either glioma, meningioma, pituitary, or no tumor.\n","\n","    The saliency map highlights the regions of the image that the machine learning model is focusing on to make the prediction.\n","\n","    The deep learning model predicted the image to be of class '{model_prediction}' with a confidence of {confidence * 100}%.\n","\n","    In your response:\n","    - Explain what regions of the brain the model is focusing on, based on the saliency map. Refer to the regions highlighted\n","    in light cyan, those are the regions where the model is focusing on.\n","    - Explain possible reasons why the model made the prediction it did.\n","    - Don't mention anything like 'The saliency map highlights the regions the model is focusing on, which are in light cyan'\n","    in your explanation.\n","    - Keep your explanation to 4 sentences max.\n","    \"\"\"\n","\n","    img = PIL.Image.open(img_path)\n","\n","    model = genai.GenerativeModel(model_name=\"gemini-1.5-flash\")\n","    response = model.generate_content([prompt, img])\n","\n","    return response.text\n","\n","def generate_saliency_map(model, img_array, class_index, img_size):\n","    \"\"\"\n","    Creates a visual representation (saliency map) highlighting areas of a brain MRI image that are most important for the model's prediction. Thus, enhancing transparency and trust in the output.\n","    \"\"\"\n","\n","    # Compute gradients of the target class with respect to the input image\n","    with tf.GradientTape() as tape:\n","        img_tensor = tf.convert_to_tensor(img_array)\n","        tape.watch(img_tensor)\n","        predictions = model(img_tensor)\n","        target_class = predictions[:, class_index]\n","\n","    # Gradient processing\n","    gradients = tape.gradient(target_class, img_tensor)\n","    gradients = tf.math.abs(gradients)\n","    gradients = tf.reduce_max(gradients, axis=-1)\n","    gradients = gradients.numpy().squeeze()\n","\n","    # Resize gradients to match original image size\n","    gradients = cv2.resize(gradients, img_size)\n","\n","    # Create a circular mask for the brain area\n","    center = (gradients.shape[0] // 2, gradients.shape[1] // 2)\n","    radius = min(center[0], center[1]) - 10\n","    y, x = np.ogrid[:gradients.shape[0], :gradients.shape[1]]\n","    mask = (x - center[0])**2 + (y - center[1])**2 <= radius**2\n","\n","    # Apply mask to gradients\n","    gradients = gradients * mask\n","\n","    # Normalize only the brain area\n","    brain_gradients = gradients[mask]\n","    if brain_gradients.max() > brain_gradients.min():\n","        brain_gradients = (brain_gradients - brain_gradients.min()) / (brain_gradients.max() - brain_gradients.min())\n","    gradients[mask] = brain_gradients\n","\n","    # Apply a higher threshold\n","    threshold = np.percentile(gradients[mask], 80)\n","    gradients[gradients < threshold] = 0\n","\n","    # Apply more aggressive smoothing\n","    gradients = cv2.GaussianBlur(gradients, (11, 11), 0)\n","\n","    # Create a heatmap overlay with enhanced contrast\n","    heatmap = cv2.applyColorMap(np.uint8(255 * gradients), cv2.COLORMAP_JET)\n","    heatmap = cv2.cvtColor(heatmap, cv2.COLOR_BGR2RGB)\n","\n","    # Resize heatmap to match original image size\n","    heatmap = cv2.resize(heatmap, img_size)\n","\n","    # Superimpose the heatmap on original image with increased opacity\n","    original_img = image.img_to_array(img)\n","    superimposed_img = heatmap * 0.7 + original_img * 0.3\n","    superimposed_img = superimposed_img.astype(np.uint8)\n","\n","    # Save the original uploaded image\n","    img_path = os.path.join(output_dir, uploaded_file.name)\n","    with open(img_path, \"wb\") as f:\n","        f.write(uploaded_file.getbuffer())\n","\n","    # Define path and save the saliency map\n","    saliency_map_path = f'saliency_maps/{uploaded_file.name}'\n","    cv2.imwrite(saliency_map_path, cv2.cvtColor(superimposed_img, cv2.COLOR_RGB2BGR))\n","\n","    return superimposed_img\n","\n","def load_transfered_model(model_name, model_path, img_size):\n","    img_shape=(img_size,img_size,3)\n","    if model_name == \"Xception\":\n","        base_model = tf.keras.applications.Xception(include_top=False, weights=\"imagenet\",\n","                                                  input_shape=img_shape, pooling='max')\n","    elif model_name == \"EfficientNetB3\":\n","        base_model = tf.keras.applications.EfficientNetB3(include_top=False, weights=\"imagenet\",\n","                                                  input_shape=img_shape, pooling='max')\n","\n","    model = Sequential([\n","        base_model,\n","        Flatten(),\n","        Dropout(rate=0.3),\n","        Dense(128, activation='relu'),\n","        Dropout(rate=0.25),\n","        Dense(4, activation='softmax')\n","    ])\n","\n","    model.build((None,) + img_shape)\n","\n","    # Compile the model\n","    model.compile(Adamax(learning_rate=0.001),\n","                 loss='categorical_crossentropy',\n","                 metrics=['accuracy',\n","                         Precision(),\n","                         Recall()])\n","\n","    model.load_weights(model_path)\n","\n","    return model\n","\n","def img_data_prep(img):\n","    \"\"\"\n","    Image Data Preparation: convert to array, normalize and expand dimensions\n","    \"\"\"\n","    img_array = image.img_to_array(img)\n","    img_array = np.expand_dims(img_array, axis=0) # convert image to an array\n","    img_array /= 255.0 # normalization\n","    return img_array\n","\n","def get_predictions(img_array):\n","    \"\"\"\n","    Get predictions from the model\n","    \"\"\"\n","    prediction = model.predict(img_array)\n","    return prediction        \n","\n","# BUILD UI\n","st.title(\"Brain Tumor Classification\")\n","st.write(\"Upload an image of a brain MRI scan to classify.\")\n","\n","uploaded_file = st.file_uploader(\"Choose an image...\", type=[\"jpg\", \"jpeg\", \"png\"])\n","\n","if uploaded_file is not None:\n","\n","    # SELECT A PREDICTION MODEL\n","    selected_model = st.radio(\n","        \"Select Model\",\n","        (\"Transfer Learning - Xception\", \"Transfer Learning - EfficientNetB3\", \"CNN 1M-Parameters\", \"CNN 4M7-Parameters\")\n","    )\n","\n","    if selected_model == \"Transfer Learning - Xception\":\n","        model = load_transfered_model('Xception', './models/xception_model.weights.h5', 299)\n","        img_size = (299, 299)\n","    elif selected_model == \"Transfer Learning - EfficientNetB3\":\n","        model = load_transfered_model('EfficientNetB3', './models/efficientnet_model.weights.h5', 300)\n","        img_size = (300, 300)\n","    elif selected_model == \"CNN 1M-Parameters\":\n","        model = load_model('./models/cnn_model_1M0.h5')\n","        img_size = (224, 224)\n","    else:\n","        model = load_model('./models/cnn_model_4M7.h5')\n","        img_size = (224, 224)\n","\n","    # LIST PREDICTIONS\n","    labels = ['Glioma', 'Meningioma', 'No tumor', 'Pituitary']\n","\n","    img = image.load_img(uploaded_file, target_size=img_size)\n","    img_array = img_data_prep(img)\n","    predictions = get_predictions(img_array)\n","\n","    # Get the class with the highest probability\n","    class_index = np.argmax(predictions[0])\n","    result = labels[class_index]\n","\n","    # st.write(f\"Predicted Class: {result}\")\n","    # st.write(\"Predictions:\")\n","    # for label, prob in zip(labels, predictions[0]):\n","    #     st.write(f\"{label}: {prob:.4f}\")\n","\n","    class_index = np.argmax(predictions[0])\n","    result = labels[class_index]\n","\n","    st.write(\"## Classification Results\")\n","\n","    result_container = st.container()\n","    result_container = st.container()\n","\n","    result_container.markdown(f\"\"\"\n","    <div style=\"background-color: #000000; color: #ffffff; padding: 30px; border-radius: 15px;\">\n","        <div style=\"display: flex; justify-content: space-between; align-items: center;\">\n","            <div style=\"flex: 1; text-align: center;\">\n","                <h3 style=\"color: #ffffff; margin-bottom: 10px; font-size: 20px;\">Prediction</h3>\n","                <p style=\"font-size: 36px; font-weight: 800; color: #FF0000; margin: 0;\">{result}</p>\n","            </div>\n","            <div style=\"width: 2px; height: 80px; background-color: #ffffff; margin: 0 20px;\"></div>\n","            <div style=\"flex: 1; text-align: center;\">\n","                <h3 style=\"color: #ffffff; margin-bottom: 10px; font-size: 20px;\">Confidence</h3>\n","                <p style=\"font-size: 36px; font-weight: 800; color: #2196F3; margin: 0;\">{predictions[0][class_index]:.4%}</p>\n","            </div>\n","        </div>\n","    </div>\n","    \"\"\", unsafe_allow_html=True)\n","\n","    # Prepare data for Plotly chart\n","    probabilities = predictions[0]\n","    sorted_indices = np.argsort(probabilities)[::-1]\n","    sorted_labels = [labels[i] for i in sorted_indices]\n","    sorted_probabilities = probabilities[sorted_indices]\n","\n","    # Create a Plotly bar chart\n","    fig = go.Figure(go.Bar(\n","        x=sorted_probabilities,\n","        y=sorted_labels,\n","        orientation='h',\n","        marker_color=['red' if label == result else 'blue' for label in sorted_labels]\n","    ))\n","\n","    # Customize the chart layout\n","    fig.update_layout(\n","        title='Probabilities for each class',\n","        xaxis_title='Probability',\n","        yaxis_title='Class',\n","        height=400,\n","        width=600,\n","        yaxis=dict(autorange=\"reversed\")\n","    )\n","\n","    # Add value labels to the bars\n","    for i, prob in enumerate(sorted_probabilities):\n","        fig.add_annotation(\n","            x=prob,\n","            y=i,\n","            text=f'{prob:.4f}',\n","            showarrow=False,\n","            xanchor='left',\n","            xshift=5\n","        )\n","\n","    st.plotly_chart(fig)\n","\n","    saliency_map = generate_saliency_map(model, img_array, class_index, img_size)\n","    saliency_map_path = f'saliency_maps/{uploaded_file.name}'\n","    explanation = generate_explanation(saliency_map_path, result, predictions[0][class_index])\n","\n","    st.write(\"## Explanation\")\n","    st.write(explanation)\n","    with st.expander(\"MRI Scan Image - Saliency Map\"):\n","        col1, col2 = st.columns(2)\n","        with col1:\n","            st.image(uploaded_file, caption='Uploaded Image', use_container_width=True)\n","        with col2:\n","            st.image(saliency_map,\n","                    caption='Saliency Map',\n","                    use_container_width=True)\n","        "]},{"cell_type":"code","execution_count":8,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":12,"status":"ok","timestamp":1730947420598,"user":{"displayName":"Braulio Fernandes","userId":"15281912688788735537"},"user_tz":300},"id":"NRXt8Ovb3Kia","outputId":"5da2e269-2817-4399-b31a-1af7fc58ac05"},"outputs":[{"name":"stdout","output_type":"stream","text":["Public URL: NgrokTunnel: \"https://7330-130-44-115-209.ngrok-free.app\" -> \"http://localhost:3005\"\n"]},{"name":"stdout","output_type":"stream","text":["\n","  You can now view your Streamlit app in your browser.\n","\n","  Local URL: http://localhost:3005\n","  Network URL: http://192.168.4.25:3005\n","\n","  For better performance, install the Watchdog module:\n","\n","  $ xcode-select --install\n","  $ pip install watchdog\n","            \n"]},{"name":"stderr","output_type":"stream","text":["2024-11-14 21:41:36.695841: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n","To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n","/usr/local/lib/python3.11/site-packages/keras/src/saving/saving_lib.py:719: UserWarning: Skipping variable loading for optimizer 'adamax', because it has 2 variables whereas the saved optimizer has 318 variables. \n","  saveable.load_own_variables(weights_store.get(inner_path))\n"]},{"name":"stdout","output_type":"stream","text":["\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1s/step\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.11/site-packages/keras/src/saving/saving_lib.py:719: UserWarning:\n","\n","Skipping variable loading for optimizer 'adamax', because it has 2 variables whereas the saved optimizer has 686 variables. \n","\n"]},{"name":"stdout","output_type":"stream","text":["\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n"]},{"name":"stderr","output_type":"stream","text":["WARNING:absl:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"]},{"name":"stdout","output_type":"stream","text":["\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 88ms/step\n"]},{"name":"stderr","output_type":"stream","text":["WARNING:absl:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"]},{"name":"stdout","output_type":"stream","text":["\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 288ms/step\n"]}],"source":["thread = Thread(target=run_streamlit)\n","thread.start()\n","\n","public_url = ngrok.connect(addr='3005', proto='http', bind_tls=True)\n","print(\"Public URL:\", public_url)"]}],"metadata":{"accelerator":"GPU","colab":{"authorship_tag":"ABX9TyNvCeHM7CJzO022zGNbjD8W","gpuType":"T4","provenance":[]},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.11.6"}},"nbformat":4,"nbformat_minor":0}
